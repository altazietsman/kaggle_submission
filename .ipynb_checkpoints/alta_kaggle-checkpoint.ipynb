{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Climate Change Belief Challenge\n",
    "\n",
    "Alta Saunders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aim\n",
    "\n",
    "Develop a machine leraning model that can predict whether people belief in Climate Change based on tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplied Data sets\n",
    "\n",
    "- train.csv (should be used to train data)\n",
    "- test.csv (should be used to test data and excludes arrival times)\n",
    "- example of submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and viewing of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('C:/Users/alta/Documents/GitHub/kaggle/train.csv')\n",
    "df_test = pd.read_csv('C:/Users/alta/Documents/GitHub/kaggle/test.csv')\n",
    "df_sub = pd.read_csv('C:/Users/alta/Documents/GitHub/kaggle/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>169760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>35326</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>224985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>476263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>872928</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweetid  sentiment\n",
       "0   169760          1\n",
       "1    35326          1\n",
       "2   224985          1\n",
       "3   476263          1\n",
       "4   872928          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make lower case\n",
    "df_train['message'] = df_train['message'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctuation\n",
    "import string\n",
    "\n",
    "def remove_punctuation_numbers(tweet):\n",
    "    punc_numbers = string.punctuation + '0123456789'\n",
    "    return ''.join([l for l in tweet if l not in punc_numbers])\n",
    "\n",
    "df_train['message'] = df_train['message'].apply(remove_punctuation_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer(stop_words='english', min_df= .01)\n",
    "X = vect.fit_transform(df_train['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X.A, columns=vect.get_feature_names())\n",
    "X = pd.DataFrame(X.A, columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['action', 'amp', 'believe', 'carbon', 'cause', 'change', 'chief',\n",
       "       'china', 'chinese', 'climate', 'climatechange', 'cnn', 'combat',\n",
       "       'denier', 'deniers', 'die', 'does', 'doesnt', 'donald', 'dont', 'earth',\n",
       "       'energy', 'environment', 'epa', 'fight', 'future', 'global', 'going',\n",
       "       'good', 'great', 'head', 'help', 'hoax', 'https', 'httpst', 'httpstco',\n",
       "       'httpstcosjofonã', 'husband', 'ice', 'im', 'isnt', 'issue', 'just',\n",
       "       'know', 'like', 'make', 'man', 'millions', 'mr', 'need', 'new', 'news',\n",
       "       'obama', 'order', 'paris', 'people', 'planet', 'president',\n",
       "       'presidentelect', 'pruitt', 'real', 'realdonaldtrump', 'really',\n",
       "       'right', 'rt', 'say', 'says', 'science', 'scientists', 'scott',\n",
       "       'sensanders', 'shes', 'stephenschlegel', 'stop', 'think', 'thinking',\n",
       "       'thinks', 'time', 'today', 'trump', 'trumps', 'tã', 'want', 'warming',\n",
       "       'watch', 'weather', 'world', 'years'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add sentiment and to dataframe\n",
    "y = df_train['sentiment']\n",
    "\n",
    "df['y'] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train and test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create models\n",
    "\n",
    "lr = LogisticRegression() \n",
    "kn = KNeighborsClassifier(5)\n",
    "svc_linear = SVC(kernel=\"linear\", C=0.05)\n",
    "svc = SVC(gamma=2, C=1)\n",
    "dtc = DecisionTreeClassifier(max_depth=10)\n",
    "rfc = RandomForestClassifier(max_depth=10, n_estimators=10)\n",
    "abc = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model on train data\n",
    "lr.fit(X_train, y_train)\n",
    "kn.fit(X_train, y_train)\n",
    "svc_linear.fit(X_train, y_train)\n",
    "svc.fit(X_train, y_train)\n",
    "dtc.fit(X_train, y_train)\n",
    "rfc.fit(X_train, y_train)\n",
    "abc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict on test data\n",
    "lr_pred = lr.predict(X_test)\n",
    "kn_pred = kn.predict(X_test)\n",
    "svc_linear_pred = svc_linear.predict(X_test)\n",
    "svc_pred =  svc.predict(X_test)\n",
    "dtc_pred = dtc.predict(X_test)\n",
    "rfc_pred = rfc.predict(X_test) \n",
    "abc_pred = abc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_a  = metrics.accuracy_score(y_test, lr_pred)\n",
    "kn_a  = metrics.accuracy_score(y_test, kn_pred)\n",
    "svc_linear_a  = metrics.accuracy_score(y_test, svc_linear_pred)\n",
    "svc_a  = metrics.accuracy_score(y_test, svc_pred)\n",
    "dtc_a  = metrics.accuracy_score(y_test, dtc_pred)\n",
    "rfc_a  = metrics.accuracy_score(y_test, rfc_pred)\n",
    "abc_a  = metrics.accuracy_score(y_test, abc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.6017699115044248\n",
      "kn:  0.5448798988621998\n",
      "svc_linear:  0.5871049304677624\n",
      "svc:  0.6207332490518331\n",
      "dtc:  0.5843236409608091\n",
      "rfc : 0.5893805309734513\n",
      "abc : 0.5901390644753477\n"
     ]
    }
   ],
   "source": [
    "print('lr: ', lr_a)\n",
    "print('kn: ', kn_a)\n",
    "print('svc_linear: ', svc_linear_a)\n",
    "print('svc: ', svc_a)\n",
    "print('dtc: ', dtc_a)\n",
    "print('rfc :', rfc_a)\n",
    "print('abc :', abc_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_p  = metrics.precision_score(y_test, lr_pred, average='micro')\n",
    "kn_p  = metrics.precision_score(y_test, kn_pred, average='micro')\n",
    "svc_linear_p  = metrics.precision_score(y_test, svc_linear_pred, average='micro')\n",
    "svc_p  = metrics.precision_score(y_test, svc_pred, average='micro')\n",
    "dtc_p  = metrics.precision_score(y_test, dtc_pred, average='micro')\n",
    "rfc_p  = metrics.precision_score(y_test, rfc_pred, average='micro')\n",
    "abc_p  = metrics.precision_score(y_test, abc_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.6017699115044248\n",
      "kn:  0.5448798988621998\n",
      "svc_linear:  0.5871049304677624\n",
      "svc:  0.6207332490518331\n",
      "dtc:  0.5843236409608091\n",
      "rfc : 0.5893805309734513\n",
      "abc : 0.5901390644753477\n"
     ]
    }
   ],
   "source": [
    "print('lr: ', lr_p)\n",
    "print('kn: ', kn_p)\n",
    "print('svc_linear: ', svc_linear_p)\n",
    "print('svc: ', svc_p)\n",
    "print('dtc: ', dtc_p)\n",
    "print('rfc :', rfc_p)\n",
    "print('abc :', abc_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_r  = metrics.recall_score(y_test, lr_pred, average='micro')\n",
    "kn_r  = metrics.recall_score(y_test, kn_pred, average='micro')\n",
    "svc_linear_r  = metrics.recall_score(y_test, svc_linear_pred, average='micro')\n",
    "svc_r  = metrics.recall_score(y_test, svc_pred, average='micro')\n",
    "dtc_r  = metrics.recall_score(y_test, dtc_pred, average='micro')\n",
    "rfc_r  = metrics.recall_score(y_test, rfc_pred, average='micro')\n",
    "abc_r  = metrics.recall_score(y_test, abc_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.6017699115044248\n",
      "kn:  0.5448798988621998\n",
      "svc_linear:  0.5871049304677624\n",
      "svc:  0.6207332490518331\n",
      "dtc:  0.5843236409608091\n",
      "rfc : 0.5893805309734513\n",
      "abc : 0.5901390644753477\n"
     ]
    }
   ],
   "source": [
    "print('lr: ', lr_r)\n",
    "print('kn: ', kn_r)\n",
    "print('svc_linear: ', svc_linear_r)\n",
    "print('svc: ', svc_r)\n",
    "print('dtc: ', dtc_r)\n",
    "print('rfc :', rfc_r)\n",
    "print('abc :', abc_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_f1  = metrics.f1_score(y_test, lr_pred, average='micro')\n",
    "kn_f1  = metrics.f1_score(y_test, kn_pred, average='micro')\n",
    "svc_linear_f1  = metrics.f1_score(y_test, svc_linear_pred, average='micro')\n",
    "svc_f1  = metrics.f1_score(y_test, svc_pred, average='micro')\n",
    "dtc_f1  = metrics.f1_score(y_test, dtc_pred, average='micro')\n",
    "rfc_f1  = metrics.f1_score(y_test, rfc_pred, average='micro')\n",
    "abc_f1  = metrics.f1_score(y_test, abc_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.6017699115044248\n",
      "kn:  0.5448798988621998\n",
      "svc_linear:  0.5871049304677624\n",
      "svc:  0.6207332490518331\n",
      "dtc:  0.5843236409608091\n",
      "rfc : 0.5893805309734513\n",
      "abc : 0.5901390644753477\n"
     ]
    }
   ],
   "source": [
    "print('lr: ', lr_f1)\n",
    "print('kn: ', kn_f1)\n",
    "print('svc_linear: ', svc_linear_f1)\n",
    "print('svc: ', svc_f1)\n",
    "print('dtc: ', dtc_f1)\n",
    "print('rfc :', rfc_f1)\n",
    "print('abc :', abc_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since SVC model did the best, we will start with the hyper parameter tuning for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10],\n",
       "                         'gamma': [0.001, 0.01, 0.1, 1]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_micro', verbose=0)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfolds = 2\n",
    "\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "\n",
    "param_grid = {\n",
    "    'C'     : Cs, \n",
    "    'gamma' : gammas\n",
    "    }\n",
    "\n",
    "grid_SVM = GridSearchCV(SVC(), param_grid, scoring='f1_micro', cv=nfolds)\n",
    "grid_SVM.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 1}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_SVM.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets use to new hyperparamers and see if there is an improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_new = SVC(gamma=1, C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf', max_iter=-1,\n",
       "    probability=False, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_new.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_new_pred =  svc_new.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc_new:  0.6343868520859671\n"
     ]
    }
   ],
   "source": [
    "svc_f1_new  = metrics.f1_score(y_test, svc_new_pred, average='micro')\n",
    "print('svc_new: ', svc_f1_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model to be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_saved_path = 'C:/Users/alta/Documents/Explore/Trains/Sprint 6/kaggle/svc.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_saved_path, 'wb') as file: pickle.dump(svc_new, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
