{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Climate Change Belief Challenge\n",
    "\n",
    "Alta Saunders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aim\n",
    "\n",
    "Develop a machine leraning model that can predict whether people belief in Climate Change based on tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplied Data sets\n",
    "\n",
    "- train.csv (should be used to train data)\n",
    "- test.csv (should be used to test data and excludes arrival times)\n",
    "- example of submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and viewing of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "df_sub = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\16983521\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('words')\n",
    "words = set(nltk.corpus.words.words())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View data to see how to best clean it and remove noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To clean data we can remove the @.... strings, we can remove punctuation and make everything lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_tweets = r'(RT)|(@[A-Za-z0-9]+)'\n",
    "pattern_url = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = df_train['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_clean = []\n",
    "\n",
    "from string import punctuation\n",
    "my_punctuation = punctuation.replace(\"'\", \"\")\n",
    "\n",
    "for x in tweets:\n",
    "    new = ' '.join(re.sub(pattern_tweets,\" \",x).split())\n",
    "    new1 = ' '.join(re.sub(pattern_url,\" \",new).split())\n",
    "    new2 = new1.translate(str.maketrans(\"\", \"\", my_punctuation))\n",
    "    new3 = ' '.join(re.sub(r'[^a-zA-Z]', \" \",new2).split())\n",
    "   \n",
    "    tweets_clean.append(new3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are non-english tweets in the training dataset, however there are very few non-english tweets in the test dataset. We do not want to train our model on non-englisg tokens> Lets remove all non-englisjh characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15819"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['message'] = tweets_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make lower case\n",
    "df_train['message'] = df_train['message'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_clean['sentiment'].value_counts().plot(kind = 'bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a clear disparity in the distribution of the data (2,0,-1 are under represented). Everything needs to be equal before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicies of each group\n",
    "sentiment_0 = df_clean[df_clean.sentiment == 0]\n",
    "sentiment_1 = df_clean[df_clean.sentiment == 1]\n",
    "sentiment_2 = df_clean[df_clean.sentiment == 2]\n",
    "sentiment_n1 = df_clean[df_clean.sentiment == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get length of majority sentiment\n",
    "n_sentiment2 = len(sentiment_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample majorityclass\n",
    "sentiment_0_upsampled = resample(sentiment_0, replace=True, n_samples=n_sentiment2, random_state=50) \n",
    "sentiment_1_upsampled = resample(sentiment_1, replace=True, n_samples=n_sentiment2, random_state=50)\n",
    "sentiment_n1_upsampled = resample(sentiment_n1, replace=True, n_samples=n_sentiment2, random_state=50)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new upsampled dataframe\n",
    "df_upsampled = pd.concat([sentiment_0_upsampled, sentiment_1_upsampled,sentiment_n1_upsampled, sentiment_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_upsampled['sentiment'].value_counts().plot(kind = 'bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokeniser = TreebankWordTokenizer()\n",
    "df_upsampled['tokens'] = df_upsampled['message'].apply(tokeniser.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11385    [we, re, talking, about, this, story, on, soci...\n",
       "10030    [yes, and, the, view, will, find, a, way, to, ...\n",
       "12929    [bogar, the, celebrities, who, are, all, screa...\n",
       "14408    [how, can, people, still, try, to, deny, globa...\n",
       "13470    [kong, is, there, really, a, god, does, global...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_upsampled['tokens'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\16983521\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma(words, lemmatizer):\n",
    "    return [lemmatizer.lemmatize(word) for word in words]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_upsampled['lemma'] = df_upsampled['tokens'].apply(lemma, args=(lemmatizer, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(words, stemmer):\n",
    "    return [stemmer.stem(word) for word in words]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_upsampled['stem'] = df_upsampled['tokens'].apply(stem, args=(stemmer, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the tokens that have been broken into a lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_concat = []\n",
    "\n",
    "for x in df_upsampled['stem']:\n",
    "    lemma_concat.append(' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_upsampled['stem_concat'] = lemma_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words = 'english', ngram_range=(1,3), max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tokens = vect.fit_transform(df_upsampled['stem_concat'])\n",
    "df_tokens = pd.DataFrame(X_tokens.A, columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandon climat</th>\n",
       "      <th>abandon climat chang</th>\n",
       "      <th>abc</th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>abort</th>\n",
       "      <th>abou</th>\n",
       "      <th>abov</th>\n",
       "      <th>...</th>\n",
       "      <th>yrs</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zealot</th>\n",
       "      <th>zealotri</th>\n",
       "      <th>zero</th>\n",
       "      <th>zimmer</th>\n",
       "      <th>zimmer iceberg</th>\n",
       "      <th>zimmer iceberg global</th>\n",
       "      <th>zink</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ab  abandon  abandon climat  abandon climat chang  abc  abil  abl  abort  \\\n",
       "0  0.0      0.0             0.0                   0.0  0.0   0.0  0.0    0.0   \n",
       "1  0.0      0.0             0.0                   0.0  0.0   0.0  0.0    0.0   \n",
       "2  0.0      0.0             0.0                   0.0  0.0   0.0  0.0    0.0   \n",
       "3  0.0      0.0             0.0                   0.0  0.0   0.0  0.0    0.0   \n",
       "4  0.0      0.0             0.0                   0.0  0.0   0.0  0.0    0.0   \n",
       "\n",
       "   abou  abov  ...  yrs  zealand  zealot  zealotri  zero  zimmer  \\\n",
       "0   0.0   0.0  ...  0.0      0.0     0.0       0.0   0.0     0.0   \n",
       "1   0.0   0.0  ...  0.0      0.0     0.0       0.0   0.0     0.0   \n",
       "2   0.0   0.0  ...  0.0      0.0     0.0       0.0   0.0     0.0   \n",
       "3   0.0   0.0  ...  0.0      0.0     0.0       0.0   0.0     0.0   \n",
       "4   0.0   0.0  ...  0.0      0.0     0.0       0.0   0.0     0.0   \n",
       "\n",
       "   zimmer iceberg  zimmer iceberg global  zink  zone  \n",
       "0             0.0                    0.0   0.0   0.0  \n",
       "1             0.0                    0.0   0.0   0.0  \n",
       "2             0.0                    0.0   0.0   0.0  \n",
       "3             0.0                    0.0   0.0   0.0  \n",
       "4             0.0                    0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 10000 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add sentiment and to dataframe\n",
    "y = df_upsampled['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train and test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14560, 10000)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_tokens,y,test_size = 0.3, stratify = y, random_state = 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the var thresh model and choose a threshold\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold()\n",
    "\n",
    "# Transform (i.e.: run selection on) the training data\n",
    "X_train_vt = selector.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vt = selector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10192, 9992)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4368, 9992)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_vt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\16983521\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [  83  324 2465 4784 6845 6846 8486 8782] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
      "C:\\Users\\16983521\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "# Import the feature selector module\n",
    "from sklearn import feature_selection\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# Set up selector, choosing score function and number of features to retain\n",
    "selector_kbest = feature_selection.SelectKBest(score_func=f_classif, k=20)\n",
    "\n",
    "# Transform (i.e.: run selection on) the training data\n",
    "X_train_kbest = selector_kbest.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before generating predictions, we'll need to transform the test data the same way we did the train data\n",
    "X_test_kbest = selector_kbest.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4368, 20)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_kbest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10192, 20)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_kbest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create models\n",
    "\n",
    "lr = LogisticRegression(C=0.05, penalty='l1', solver='liblinear', verbose=1) \n",
    "kn = KNeighborsClassifier(5)\n",
    "svc = SVC(gamma=1, C=2)\n",
    "dtc = DecisionTreeClassifier(max_depth=10)\n",
    "rfc = RandomForestClassifier(max_depth=10, n_estimators=10)\n",
    "abc = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=2, gamma=1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model on train data\n",
    "#lr.fit(X_train, y_train)\n",
    "#kn.fit(X_train, y_train)\n",
    "svc.fit(X_train, y_train)\n",
    "#dtc.fit(X_train, y_train)\n",
    "#rfc.fit(X_train, y_train)\n",
    "#abc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict on test data\n",
    "#lr_pred = lr.predict(X_test)\n",
    "#kn_pred = kn.predict(X_test)\n",
    "svc_pred =  svc.predict(X_test)\n",
    "#dtc_pred = dtc.predict(X_test)\n",
    "#rfc_pred = rfc.predict(X_test) \n",
    "#abc_pred = abc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create svc models with variance selecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_kbest = SVC(gamma=1, C=2)\n",
    "svc_kbest = svc_kbest.fit(X_train_kbest, y_train)\n",
    "svc_kbest_pred = svc_kbest.predict(X_test_kbest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_vt = SVC(gamma=1, C=2)\n",
    "svc_vt = svc_vt.fit(X_train_vt, y_train)\n",
    "svc_vt_pred = svc_vt.predict(X_test_vt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr_f1  = metrics.f1_score(y_test, lr_pred, average='macro')\n",
    "#kn_f1  = metrics.f1_score(y_test, kn_pred, average='macro')\n",
    "svc_f1  = metrics.f1_score(y_test, svc_pred, average='macro')\n",
    "#dtc_f1  = metrics.f1_score(y_test, dtc_pred, average='macro')\n",
    "#rfc_f1  = metrics.f1_score(y_test, rfc_pred, average='macro')\n",
    "#abc_f1  = metrics.f1_score(y_test, abc_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc:  0.8205505315981486\n"
     ]
    }
   ],
   "source": [
    "#print('lr: ', lr_f1)\n",
    "#print('kn: ', kn_f1)\n",
    "print('svc: ', svc_f1)\n",
    "#print('dtc: ', dtc_f1)\n",
    "#print('rfc :', rfc_f1)\n",
    "#print('abc :', abc_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_f1_vt  = metrics.f1_score(y_test, svc_vt_pred, average='macro')\n",
    "svc_f1_kbest  = metrics.f1_score(y_test, svc_kbest_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vt:  0.8204837299993805\n",
      "kbest:  0.34814852889237696\n"
     ]
    }
   ],
   "source": [
    "print('vt: ', svc_f1_vt)\n",
    "print('kbest: ', svc_f1_kbest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7208238  0.73798627 0.70480549 0.6884307  0.70103093]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(svc,X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since SVC model did the best, we will start with the hyper parameter tuning for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfolds = 2\n",
    "\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "\n",
    "param_grid = {\n",
    "    'C'     : Cs, \n",
    "    'gamma' : gammas\n",
    "    }\n",
    "\n",
    "grid_SVM = GridSearchCV(SVC(), param_grid, scoring='f1_micro', cv=nfolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_SVM.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets use to new hyperparamers and see if there is an improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_new = SVC(gamma=2, C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, gamma=2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_new.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_new_pred =  svc_new.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc_new:  0.8206513736116179\n"
     ]
    }
   ],
   "source": [
    "svc_f1_new  = metrics.f1_score(y_test, svc_new_pred, average='macro')\n",
    "print('svc_new: ', svc_f1_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70366133 0.71624714 0.68077803 0.66781214 0.6930126 ]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(svc_new,X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model to be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_saved_path = 'C:/svc.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_saved_path, 'wb') as file: pickle.dump(svc, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get submission dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "df_sub = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe will now be looking to China to make su...</td>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The scary, unimpeachable evidence that climate...</td>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid\n",
       "0  Europe will now be looking to China to make su...   169760\n",
       "1  Combine this with the polling of staffers re c...    35326\n",
       "2  The scary, unimpeachable evidence that climate...   224985\n",
       "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263\n",
       "4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test = df_test['message']\n",
    "\n",
    "tweets_test_clean = []\n",
    "\n",
    "from string import punctuation\n",
    "my_punctuation = punctuation.replace(\"'\", \"\")\n",
    "\n",
    "for x in tweets_test:\n",
    "    new = ' '.join(re.sub(pattern_tweets,\" \",x).split())\n",
    "    new1 = ' '.join(re.sub(pattern_url,\" \",new).split())\n",
    "    new2 = new1.translate(str.maketrans(\"\", \"\", my_punctuation))\n",
    "    new3 = ' '.join(re.sub(r'[^a-zA-Z]', \" \",new2).split())\n",
    "   \n",
    "    tweets_test_clean.append(new3)\n",
    "    \n",
    "    \n",
    "df_test['message'] = tweets_test_clean\n",
    "\n",
    "#make lower case\n",
    "df_test['message'] = df_test['message'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_clean = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [europe, will, now, be, looking, to, china, to...\n",
       "1    [combine, this, with, the, polling, of, staffe...\n",
       "2    [the, scary, unimpeachable, evidence, that, cl...\n",
       "3    [putin, got, to, you, too, jill, trump, doesn,...\n",
       "4    [female, orgasms, cause, global, warming, sarc...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokeniser = TreebankWordTokenizer()\n",
    "df_test_clean['tokens'] = df_test_clean['message'].apply(tokeniser.tokenize)\n",
    "\n",
    "df_test_clean['tokens'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(words, stemmer):\n",
    "    return [stemmer.stem(word) for word in words]  \n",
    "\n",
    "df_test_clean['stem'] = df_test_clean['tokens'].apply(stem, args=(stemmer, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemma(words, lemmatizer):\n",
    "    return [lemmatizer.lemmatize(word) for word in words]  \n",
    "\n",
    "df_test_clean['lemma'] = df_test_clean['tokens'].apply(lemma, args=(lemmatizer, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_concat_test = []\n",
    "\n",
    "for x in df_test_clean['stem']:\n",
    "    lemma_concat_test.append(' '.join(x))\n",
    "\n",
    "df_test_clean['stem_concat'] = lemma_concat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tokens = vect.transform(df_test_clean['stem_concat'])\n",
    "df_test_tokens = pd.DataFrame(X_test_tokens.A, columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = svc.predict(df_test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_final_df = pd.DataFrame()\n",
    "\n",
    "svc_final_df['tweetid'] = df_test['tweetid']\n",
    "svc_final_df['sentiment'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "svc_final_df['sentiment'].value_counts().plot(kind = 'bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_final_df.to_csv(r'kaggle_sumbmission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
